### Description

Simple example of RAG with ollama model

### How to launch
1. Install ollama
https://ollama.com/download
2. Pull llama3.2:3b model
3. ollama run llama3.2:3b
4. pip install -r requirements.txt 
5. chainlit run rag_trial/cli_tools/rag_code_base.py
6. In the browsers open chat window - enter the path of your code folder like:
"/home/ivan/ML/monetisation-service/"
7. Enter your query about the code